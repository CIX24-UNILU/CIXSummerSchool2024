{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use LLMs-powered agents.\n",
    "\n",
    "The examples show how to use LLMs-powered agents. There are many frameworks that allow one to architect systems that solve a problem using agents. Among the most popular ones are [CrewAI](https://docs.crewai.com/) and [AutoGen](https://microsoft.github.io/autogen/docs/Getting-Started/). [LangChain](https://python.langchain.com/v0.1/docs/modules/agents/) also provides a simple framework to use agents, and that is what we will use in this notebook.\n",
    "\n",
    "This agents can use local or online models. For instructions on how to install and use local models see the `using_llms` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read secrets ------------------------------------------------\n",
    "import json\n",
    "import os\n",
    "\n",
    "# you define your on secrets.json file with the following structure\n",
    "# {\n",
    "#     \"openai\": \"your-openai-api-key\",\n",
    "#     \"groq\": \"your-groq-api-key\"\n",
    "# }\n",
    "\n",
    "with open(\"./secrets.json\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"]\n",
    "os.environ[\"GROQ_API_KEY\"] = secrets[\"groq\"]\n",
    "os.environ[\"SERPER_API_KEY\"] = secrets[\"serper_key\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of an agent using an agent that uses a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "# llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "# llm = Ollama(model=\"phi3\", temperature=0, keep_alive='10m')\n",
    "\n",
    "# using https://serper.dev/ for search - go there and get a key\n",
    "tools = load_tools([\"google-serper\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the current weather in Luxembourg, I will perform a search using the Google Search API.\n",
      "\n",
      "Action: google_serper\n",
      "Action Input: Current weather in Luxembourg\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m57°F\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The current weather in Luxembourg is 57°F.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "\n",
    "agent.run(\"What is the weather in Luxemburg?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now put things together agents, tools, and chains\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "search_prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"translate to {language} the following: {text}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "# model = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "# model = Ollama(model=\"phi3\", temperature=0, keep_alive='10m')\n",
    "\n",
    "serp_chain = search_prompt | agent\n",
    "\n",
    "translate_chain = (\n",
    "    {\"text\": serp_chain, \"language\": itemgetter(\"language\")}\n",
    "    | translate_prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "result = translate_chain.invoke({\"question\": \"what is the weather in luxemburg?\", \"language\": \"spanish\"})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-school-24-wpJ3waSW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
