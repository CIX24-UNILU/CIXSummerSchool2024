{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bookmarks Parser\n",
    "\n",
    "Code to parse and extract bookmarks from an exported HTML file from Google Chrome. The code is written in Python and uses the BeautifulSoup library to parse the HTML file. The code extracts the title and URL of each bookmark and prints them to the console.\n",
    "\n",
    "## How to export bookmarks from Google Chrome or Edge\n",
    "\n",
    "1. Open Google Chrome or Edge.\n",
    "2. Click on the three dots in the top right corner of the browser window.\n",
    "3. Click on the \"Bookmarks\" or \"Favorites\" option.\n",
    "4. Depending on your browser, you should be able to find an option to export bookmarks or favorites. This might involve selecting a bookmark manager, from which should be hopefully straightforward.\n",
    "5. Choose the location where you want to save the exported bookmarks file and click \"Save\".\n",
    "\n",
    "To be used in this example, the exported file should be in the same directory as the notebook and named `bookmarks.html`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def clean_html(html_file_path, output_file_path=None):\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "    # Remove <script> and <style> elements\n",
    "    for script_or_style in soup(['script', 'style']):\n",
    "        script_or_style.decompose()\n",
    "\n",
    "    # Remove HTML comments\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Get text from the body\n",
    "    body = soup.body\n",
    "\n",
    "    # Extract the core content text\n",
    "    text_content = body.get_text(separator='\\n', strip=True)\n",
    "\n",
    "    # Optional: Write the cleaned content to an output file\n",
    "    if output_file_path:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(text_content)\n",
    "    \n",
    "    return text_content\n",
    "\n",
    "# Example usage\n",
    "# cleaned_content = clean_html('example.html', 'cleaned_content.txt')\n",
    "# print(cleaned_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Bookmarks\n",
    "\n",
    "This code reads the exported HTML file from a Chromium browser and extracts the title and URL of each bookmark. The code uses the BeautifulSoup library to parse the HTML file and extract the required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def parse_bookmarks(html_file_path, start_date, end_date, download_dir=None):\n",
    "    ### Parse bookmarks from an HTML file exported from a browser\n",
    "    # html_file_path: path to the HTML file\n",
    "    # start_date: bookmarks starting from this date will be included\n",
    "    # end_date: bookmarks up to this date will be included\n",
    "    # download_dir: directory to save the HTML content of the bookmarks\n",
    "    \n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "        \n",
    "    bookmarks = []\n",
    "\n",
    "    # Convert date strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    def extract_bookmarks(soup_element):\n",
    "        for item in soup_element.find_all(['a', 'h3']):\n",
    "            if item.name == 'a':\n",
    "                add_date = item.get('add_date')\n",
    "                if add_date:\n",
    "                    # Convert the bookmark's add_date to a datetime object\n",
    "                    bookmark_date = datetime.fromtimestamp(int(add_date))\n",
    "                    # Check if the bookmark_date is within the specified range\n",
    "                    if start_date <= bookmark_date <= end_date:\n",
    "                        url = item.get('href')\n",
    "                        bookmark = {\n",
    "                            'title': item.get_text(),\n",
    "                            'url': url,\n",
    "                            'add_date': bookmark_date,\n",
    "                            'icon': item.get('icon'),\n",
    "                        }\n",
    "                        # Fetch and save HTML content of the bookmark if download_dir is specified\n",
    "                        if download_dir:\n",
    "                            try:\n",
    "                                response = requests.get(url)\n",
    "                                if response.status_code == 200:\n",
    "                                    html_content = response.text # HTML content of the page - clean it if needed\n",
    "                                    file_name = f\"{bookmark_date.strftime('%Y%m%d%H%M%S')}_{item.get_text().replace(' ', '_')}.html\"\n",
    "                                    file_path = os.path.join(download_dir, file_name)\n",
    "                                    with open(file_path, 'w', encoding='utf-8') as html_file:\n",
    "                                        html_file.write(html_content)\n",
    "                                    bookmark['html_file'] = file_path\n",
    "                            except requests.exceptions.RequestException as e:\n",
    "                                print(f\"Error fetching {url}: {e}\")\n",
    "                        \n",
    "                        bookmarks.append(bookmark)\n",
    "            elif item.name == 'h3':\n",
    "                folder_name = item.get_text()\n",
    "                folder = {\n",
    "                    'folder_name': folder_name,\n",
    "                    'bookmarks': []\n",
    "                }\n",
    "                bookmarks.append(folder)\n",
    "                next_sibling = item.find_next_sibling()\n",
    "                if next_sibling and next_sibling.name == 'dl':\n",
    "                    extract_bookmarks(next_sibling)\n",
    "    \n",
    "    extract_bookmarks(soup.body)\n",
    "    \n",
    "    return bookmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "download_dir = 'downloaded_bookmarks_html'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# bookmarks = parse_bookmarks('bookmarks.html', '2022-01-01', '2022-12-31', download_dir)\n",
    "# for bookmark in bookmarks:\n",
    "#     print(bookmark)\n",
    "\n",
    "# Example usage without downloading HTML\n",
    "bookmarks_without_download = parse_bookmarks('bookmarks.html', '2022-01-01', '2022-12-31')\n",
    "for bookmark in bookmarks_without_download:\n",
    "    print(bookmark)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-school-24-wpJ3waSW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
