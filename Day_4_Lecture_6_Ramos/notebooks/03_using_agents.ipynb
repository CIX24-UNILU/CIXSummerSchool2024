{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use LLMs-powered agents.\n",
    "\n",
    "The examples show how to use LLMs-powered agents. There are many frameworks that allow one to architect systems that solve a problem using agents. Among the most popular ones are [CrewAI](https://docs.crewai.com/) and [AutoGen](https://microsoft.github.io/autogen/docs/Getting-Started/). [LangChain](https://python.langchain.com/v0.1/docs/modules/agents/) also provides a simple framework to use agents, and that is what we will use in this notebook.\n",
    "\n",
    "This agents can use local or online models. For instructions on how to install and use local models see the `using_llms` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read secrets ------------------------------------------------\n",
    "import json\n",
    "import os\n",
    "\n",
    "# you define your on secrets.json file with the following structure\n",
    "# {\n",
    "#     \"openai\": \"your-openai-api-key\",\n",
    "#     \"groq\": \"your-groq-api-key\"\n",
    "# }\n",
    "\n",
    "with open(\"./secrets.json\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"]\n",
    "os.environ[\"GROQ_API_KEY\"] = secrets[\"groq\"]\n",
    "os.environ[\"SERPER_API_KEY\"] = secrets[\"serper_key\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of an agent using an agent that uses a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    load_tools,\n",
    "    create_tool_calling_agent\n",
    ")\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "# llm = Ollama(model=\"phi3\", temperature=0, keep_alive='10m')\n",
    "\n",
    "# using https://serper.dev/ for search - go there and get a key\n",
    "tools = load_tools([\"google-serper\"], llm=llm)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(tools=tools, llm=llm, prompt=prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "agent_executor.invoke({\"input\": \"What is the weather in Luxemburg?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now put things together agents, tools, and chains\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "search_prompt = ChatPromptTemplate.from_template(\"{question}\")\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"translate to {language} the following: {text}\"\n",
    ")\n",
    "\n",
    "# model = ChatOpenAI()\n",
    "# model = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "model = Ollama(model=\"phi3\", temperature=0, keep_alive='10m')\n",
    "\n",
    "serp_chain = {\"input\": search_prompt} | agent_executor \n",
    "\n",
    "translate_chain = (\n",
    "    {\"text\": serp_chain, \"language\": itemgetter(\"language\")}\n",
    "    | translate_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = translate_chain.invoke({\"question\": \"what is the weather in luxemburg (in metric units)?\", \"language\": \"spanish\"})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-school-24-wpJ3waSW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
