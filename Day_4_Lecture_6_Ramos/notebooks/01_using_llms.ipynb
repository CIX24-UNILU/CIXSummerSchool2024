{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use LLMs.\n",
    "\n",
    "The examples show how to use LLMs from a local model - using Ollama - and from an external model - using OpenAI.\n",
    "\n",
    "## Using a local model\n",
    "\n",
    "Using a local model has the advantage of being able to run the model offline. The disadvantage is that the model may not be as good as a model from a large company like OpenAI.\n",
    "\n",
    "To install Ollama, follow the instructions at their [download homepage](https://ollama.com/download).\n",
    "\n",
    "Once you have Ollama installed, you need to dpwnload a model. You can see the available models from the [Ollama models page](https://ollama.com/models). For example, to install _llama3_ you will type on your terminal.\n",
    "\n",
    "```bash\n",
    "ollama pull mistral\n",
    "```\n",
    "\n",
    "You can then use the model directly using ollama's [RESTful API](https://github.com/ollama/ollama/blob/main/docs/api.md).\n",
    "\n",
    "In this notebook, we will show how to use [LangChain](https://python.langchain.com/v0.2/docs/introduction/) to interact with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhy did the chicken go to the doctor?\\n\\nBecause it had fowl breath!\\n\\nHope that made you cluck with laughter!\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = Ollama(model=\"llama3\", temperature=0.25, keep_alive='10m')\n",
    "parser = StrOutputParser()\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"\"), (\"user\", \"Tell me a joke about {topic}\")])\n",
    "\n",
    "chain = template | llm | parser\n",
    "chain.invoke({\"topic\": \"chickens\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an external model\n",
    "\n",
    "Using an external model has the advantage of accesing more powerful models. The disadvantage is that you need to have an internet connection, and pay $$ to use the model.\n",
    "\n",
    "This notebook assumes that you know how to get an API key from OpenAI, and that the key is stored in an environment variable called `OPENAI_API_KEY`.\n",
    "\n",
    "Other options are available, like [Groq](https://groq.com/), Mistral and Anthropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read secrets ------------------------------------------------\n",
    "import json\n",
    "import os\n",
    "\n",
    "# you define your on secrets.json file with the following structure\n",
    "# {\n",
    "#     \"openai\": \"your-openai-api-key\",\n",
    "#     \"groq\": \"your-groq-api-key\"\n",
    "# }\n",
    "\n",
    "with open(\"./secrets.json\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"openai\"]\n",
    "os.environ[\"GROQ_API_KEY\"] = secrets[\"groq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"¿Por qué la gallina no puede usar el teléfono? Porque cuando quiere marcar, pone un huevo. \\n\\nTranslation: Why can't the chicken use the telephone? Because when she wants to dial, she lays an egg.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = ChatGroq(temperature=0.25, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"You only communicate in {language}\"), (\"user\", \"Tell me a joke about {topic}\")])\n",
    "\n",
    "chain = template | model | parser\n",
    "chain.invoke({\"topic\": \"chickens\", \"language\": \"spanish\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Using a model to summarize a document\n",
    "\n",
    "In this example, we will use a model to summarize a document. We assume that that the document is local and its called `Personal_Fitness_Tracker.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load a document\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "files = [\"./documents/Personal_Fitness_Tracker.html\"]\n",
    "loader = UnstructuredFileLoader(files, show_progress=True)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The document provides a comprehensive analysis of the personal fitness tracker market, discussing market growth, competitive landscape, SWOT analysis, and user research insights. The executive summary effectively conveys the key findings, but a few areas can be improved for clarity and coherence. First, the opening sentence could be more concise, directly stating that the personal fitness tracker market is growing due to increasing health awareness and wearable technology adoption. Second, the transition between the first and second paragraphs could be smoother, for example, by introducing the market growth figures in the executive summary instead of repeating them from the main text. Lastly, the last sentence of the document could be rephrased to emphasize the importance of addressing consumer concerns and preferences for companies to stay competitive and drive market growth. Overall, the document is well-organized and informative, providing valuable insights into the personal fitness tracker market.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then lets use templates to make an editor that can do different operation on a document\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = ChatGroq(temperature=0.25, model_name=\"mixtral-8x7b-32768\")\n",
    "# model = Ollama(model=\"phi3\", temperature=0.25, keep_alive='10m')\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([(\"system\", \"You are a capable copyeditor.\"), (\"user\", \"Perform the following operation {operation} the following document {document}\")])\n",
    "\n",
    "chain = template | model | parser\n",
    "chain.invoke({\"operation\": \"critique in one paragraph\", \"document\": docs[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-school-24-wpJ3waSW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
