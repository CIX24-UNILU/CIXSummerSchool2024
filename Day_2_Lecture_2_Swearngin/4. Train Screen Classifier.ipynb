{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2ca318-84ba-42ca-94bc-c7f88c6da5cb",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a screen classification model on the Enrico dataset. Screen classification classifies a whole screen into one of 20 possible screen categories such as `media player` or `login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57be3f4-079b-4854-828b-3bc00a996751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from screenclassification.ui_datasets import *\n",
    "from screenclassification.ui_models import *\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import *\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import os\n",
    "\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c64781a-2faa-40fe-8b71-5698f1c1a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_DIR = \"checkpoints_screenclassification_imagenet-enrico\"\n",
    "CHECK_INTERVAL_STEPS = 8000\n",
    "\n",
    "if not os.path.exists(ARTIFACT_DIR):\n",
    "    os.makedirs(ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a3aefb8-c097-4f24-9e86-b4873eebd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ac5dd-caa8-4a66-b2fd-238e0534f9f1",
   "metadata": {},
   "source": [
    "## Create the data module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d5839-7084-46d8-8cf2-879ac6fd649e",
   "metadata": {},
   "source": [
    "This model uses the Enrico dataset (Thanks Luis!) which provides a high quality dataset of UI screens for topic modeling, or screen categorization. Enrico classifies screens into categories such as `login`, `maps`, `media player`, etc. See more about the dataset here -https://userinterfaces.aalto.fi/enrico/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed8fbb0-efbe-43db-855e-ddcd88f8c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = EnricoDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81adcd01-636f-4fc5-9e51-1cb18251a99b",
   "metadata": {},
   "source": [
    "## Instantiate the model class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f648f7e-0dd1-424c-80b3-42a8cce8d5d2",
   "metadata": {},
   "source": [
    "The screen classifier uses a resnet50 base model - documented here: https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html\n",
    "\n",
    "The ResNet model is based on the Deep Residual Learning for Image Recognition paper. It is an image classification model which we will train to recognize screen types from an input screenshot. We will use the pretrained model with weights pretrained on the ImageNet data. Then we add another layer to the output to map to the correct number of screen category classes. You can find a full list of classification models here: https://pytorch.org/vision/main/models.html#classification. To use some of these, you will likely need to modify the model definitions in the `__init__` function of `UIScreenClassifier`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15653bbe-d993-4749-ad86-2957efa9e383",
   "metadata": {},
   "source": [
    "model = UIScreenClassifier(num_classes=20, arch=\"resnet50pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70067285-3351-422b-a06f-0ac0be2e9e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      "checkpoints: []\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***********************************\")\n",
    "print(\"checkpoints: \" + str(os.listdir(ARTIFACT_DIR)))\n",
    "print(\"***********************************\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=ARTIFACT_DIR, every_n_train_steps=CHECK_INTERVAL_STEPS, save_last=True)\n",
    "checkpoint_callback2 = ModelCheckpoint(dirpath=ARTIFACT_DIR, filename= \"screenclassification\", monitor=\"f1_weighted\", mode=\"max\", save_top_k=1)\n",
    "earlystopping_callback = EarlyStopping(monitor=\"f1_weighted\", mode=\"max\", patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ac884e-a87f-46a2-b79e-363a4fb23eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/aswearngin/miniforge3/envs/cix-new/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:200: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='cpu',\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[checkpoint_callback, checkpoint_callback2, earlystopping_callback],\n",
    "    logger=logger,\n",
    "    accumulate_grad_batches=2,\n",
    "    min_epochs=10, \n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70aeac5-5559-4290-be0b-8addd7530a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: checkpoints_screenclassification_imagenet-enrico/lightning_logs\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | model    | ResNet     | 23.5 M\n",
      "1 | conv_cls | Sequential | 368 K \n",
      "----------------------------------------\n",
      "23.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.9 M    Total params\n",
      "95.458    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.028708133971291863, 'f1_micro': 0.1875, 'f1_weighted': 0.05921052631578947}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d09f0bb471448eb728fc6da111e73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aswearngin/miniforge3/envs/cix-new/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ce336-c101-47bc-a52a-4f3f6772f953",
   "metadata": {},
   "source": [
    "Instead of `mAP` like when you trained the UIElementDetector, this model uses 3 f1 scores. `f1_macro` takes the mean of all the per class `F1` scores. `f1_micro1` computes a global average F1 score by counting the sums of the True Positives (TP), False Negatives (FN), and False Positives (FP) and feeding them into the F1 score equation. Finally `f1_weighted` takes the mean of all per-class F1 scores while weighting them by the number of actual occurrences of the class in the dataset. Ideally, you would want to see all of these metrics continue increasing as the model trains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67de80-959c-4981-abae-9a008d2f0423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d919cc-9211-438a-a1ef-623788340741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cix-new",
   "language": "python",
   "name": "cix-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
